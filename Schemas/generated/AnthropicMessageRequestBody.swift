//
//  AnthropicMessageRequestBody.swift
//
//  Generated by api-schema-generate
//

import Foundation

/// Message request body for posts to `/v1/messages`  Send a structured list of input messages with text and/or image content, and the model will generate the next message in the conversation.  The Messages API can be used for either single queries or stateless multi-turn conversations.  All docstrings in this file are from: https://platform.claude.com/docs/en/api/messages/create
nonisolated public struct AnthropicMessageRequestBody: Encodable, Sendable {

    /// The maximum number of tokens to generate before stopping.  Note that our mode...
    public let maxTokens: Int

    /// Input messages.  Our models are trained to operate on alternating `user` and ...
    public let messages: [AnthropicMessageParam]

    /// An object describing metadata about the request.
    public let metadata: AnthropicRequestMetadata?

    /// The model that will complete your prompt.  For model strings and additional d...
    public let model: String

    /// Determines whether to use priority capacity (if available) or standard capaci...
    public let serviceTier: AnthropicServiceTierParam?

    /// Custom text sequences that will cause the model to stop generating.  Our mode...
    public let stopSequences: [String]?

    /// Whether to incrementally stream the response using server-sent events.  See h...
    public let stream: Bool?

    /// System prompt.  A system prompt is a way of providing context and instruction...
    public let system: AnthropicSystemPrompt?

    /// Amount of randomness injected into the response.  Defaults to `1.0`. Ranges f...
    public let temperature: Double?

    /// Configuration for enabling Claude's extended thinking.  When enabled, respons...
    public let thinking: AnthropicThinkingConfigParam?

    /// How the model should use the provided tools.  The model can use a specific to...
    public let toolChoice: AnthropicToolChoice?

    /// Definitions of tools that the model may use.  If you include `tools` in your ...
    public let tools: [AnthropicToolUnion]?

    /// Only sample from the top K options for each subsequent token.  Used to remove...
    public let topK: Int?

    /// Use nucleus sampling.  In nucleus sampling, we compute the cumulative distrib...
    public let topP: Double?

    private enum CodingKeys: String, CodingKey {
        case maxTokens = "max_tokens"
        case messages
        case metadata
        case model
        case serviceTier = "service_tier"
        case stopSequences = "stop_sequences"
        case stream
        case system
        case temperature
        case thinking
        case toolChoice = "tool_choice"
        case tools
        case topK = "top_k"
        case topP = "top_p"
    }

    public init(
        maxTokens: Int,
        messages: [AnthropicMessageParam],
        metadata: AnthropicRequestMetadata? = nil,
        model: String,
        serviceTier: AnthropicServiceTierParam? = nil,
        stopSequences: [String]? = nil,
        stream: Bool? = nil,
        system: AnthropicSystemPrompt? = nil,
        temperature: Double? = nil,
        thinking: AnthropicThinkingConfigParam? = nil,
        toolChoice: AnthropicToolChoice? = nil,
        tools: [AnthropicToolUnion]? = nil,
        topK: Int? = nil,
        topP: Double? = nil
    ) {
        self.maxTokens = maxTokens
        self.messages = messages
        self.metadata = metadata
        self.model = model
        self.serviceTier = serviceTier
        self.stopSequences = stopSequences
        self.stream = stream
        self.system = system
        self.temperature = temperature
        self.thinking = thinking
        self.toolChoice = toolChoice
        self.tools = tools
        self.topK = topK
        self.topP = topP
    }
}
