//
//  OpenAIModerationRequestBody.swift
//
//
//  Created by Lou Zell on 12/17/24.
//

import Foundation

/// Docstrings from https://platform.openai.com/docs/api-reference/moderations/create
public struct OpenAIModerationRequestBody: Encodable {
    /// An array of multi-modal inputs to classify.
    public let input: [ModerationInput]

    /// The model to use. E.g. "omni-moderation-latest"
    public let model: String

    // This memberwise initializer is autogenerated.
    // To regenerate, use `cmd-shift-a` > Generate Memberwise Initializer
    // To format, place the cursor in the initializer's parameter list and use `ctrl-m`
    public init(
        input: [OpenAIModerationRequestBody.ModerationInput],
        model: String
    ) {
        self.input = input
        self.model = model
    }
}

// MARK: -
extension OpenAIModerationRequestBody {
    /// Represents a single multi-modal input, which can be either text or an image.
    public enum ModerationInput: Encodable {
        /// The input text to classify
        case text(String)

        /// The input image to classify, where the image is represented as a base64-encoded data URL
        case image(String) // Create image string with AIProxy.encodeImageAsURL

        private enum RootKey: String, CodingKey {
            case imageURL = "image_url"
            case text
            case type
        }

        private enum NestedKey: String, CodingKey {
            case url
        }

        public func encode(to encoder: Encoder) throws {
            var container = encoder.container(keyedBy: RootKey.self)
            switch self {
            case .text(let textInput):
                try container.encode("text", forKey: .type)
                try container.encode(textInput, forKey: .text)
            case .image(let encodedImage):
                var nestedContainer = container.nestedContainer(keyedBy: NestedKey.self, forKey: .imageURL)
                try nestedContainer.encode(encodedImage, forKey: .url)
            }
        }
    }
}
