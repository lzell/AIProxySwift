//
//  OpenAIChatCompletionResponseBody.swift
//
//
//  Created by Lou Zell on 8/17/24.
//

import Foundation

/// https://platform.openai.com/docs/api-reference/chat/object
public struct OpenAIChatCompletionResponseBody: Decodable {
    /// A list of chat completion choices.
    /// Can be more than one if `n` on `OpenAIChatCompletionRequestBody` is greater than 1.
    public let choices: [OpenAIChatChoice]

    /// The Unix timestamp (in seconds) of when the chat completion was created.
    public let created: Int

    /// The model used for the chat completion.
    public let model: String

    /// Usage statistics for the completion request.
    public let usage: OpenAIChatUsage?

    /// This fingerprint represents the backend configuration that the model runs with.
    /// Can be used in conjunction with the `seed` request parameter to understand when
    /// backend changes have been made that might impact determinism.
    public let systemFingerprint: String?

    private enum CodingKeys: String, CodingKey {
        case choices
        case created
        case model
        case usage
        case systemFingerprint = "system_fingerprint"
    }
}

public struct OpenAIChatChoice: Decodable {
    /// The reason the model stopped generating tokens. This will be `stop` if the model hit a
    /// natural stop point or a provided stop sequence, `length` if the maximum number of
    /// tokens specified in the request was reached, `content_filter` if content was omitted
    /// due to a flag from our content filters, `tool_calls` if the model called a tool, or
    /// `function_call` (deprecated) if the model called a function.
    public let finishReason: String?

    /// A chat completion message generated by the model.
    public let message: OpenAIChoiceMessage

    private enum CodingKeys: String, CodingKey {
        case finishReason = "finish_reason"
        case message
    }
}

public struct OpenAIChoiceMessage: Decodable {
    /// The contents of the message.
    public let content: String?

    /// The role of the author of this message.
    public let role: String

    /// The tool calls generated by the model, such as function calls.
    public let toolCalls: [OpenAIToolCall]?

    private enum CodingKeys: String, CodingKey {
        case content
        case role
        case toolCalls = "tool_calls"
    }
}

public struct OpenAIToolCall: Decodable {
    /// The ID of the tool call.
    public let id: String

    /// The type of the tool. Currently, only `function` is supported.
    public let type: String

    /// The function that the model instructs us to call
    public let function: OpenAIFunction
}

public struct OpenAIFunction: Decodable {
    /// The name of the function to call.
    public let name: String

    /// The arguments to call the function with, as generated by the model in JSON format. Note
    /// that the model does not always generate valid JSON, and may hallucinate parameters not
    /// defined by your function schema. Validate the arguments in your code before calling
    /// your function.
    ///
    /// Implementor's note: I no longer think the above warning is true, now that this launched:
    /// https://openai.com/index/introducing-structured-outputs-in-the-api/
    ///
    /// The keys of the `[String: Any]` dictionary are the argument names, e.g. `location` in the guide below.
    /// The values of the `[String: Any]` dictionary are the arguments values, e.g. `Bogot√°, Colombia` in this guide:
    /// https://platform.openai.com/docs/guides/function-calling.
    public let arguments: [String: Any]?

    /// The raw arguments string, unmapped to a `[String: Any]`. The unmapped string is useful for
    /// continuing the converstation with the model. The model expects you to feed the raw argument string
    /// back to the model on susbsequent requests.
    public let argumentsRaw: String?

    private enum CodingKeys: CodingKey {
        case name
        case arguments
    }

    public init(from decoder: any Decoder) throws {
        let container = try decoder.container(keyedBy: CodingKeys.self)
        self.name = try container.decode(String.self, forKey: .name)
        if let argumentsRaw = try? container.decode(String.self, forKey: .arguments) {
            self.argumentsRaw = argumentsRaw
            self.arguments = (try [String: AIProxyJSONValue].deserialize(from: argumentsRaw)).untypedDictionary
        } else {
            self.argumentsRaw = nil
            self.arguments = nil
        }
    }
}
