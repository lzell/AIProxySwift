//
//  OpenAIFunctionShellCallResource.swift
//  AIProxy
//
//  Created by Lou Zell on 12/22/25.
//
// OpenAPI spec: FunctionShellCall, version 2.3.0, line 23345

/// A tool call that executes one or more shell commands in a managed environment.
nonisolated public struct OpenAIFunctionShellCallResource: Decodable, Sendable {
    /// The shell commands and limits that describe how to run the tool call.
    public let action: OpenAIFunctionShellAction

    /// The unique ID of the shell tool call generated by the model.
    public let callID: String

    /// The unique ID of the shell tool call. Populated when this item is returned via API.
    public let id: String

    /// The status of the shell call.
    ///
    /// One of `in_progress`, `completed`, or `incomplete`.
    public let status: OpenAILocalShellCallStatus

    /// The type of the item. Always `shell_call`.
    public let type: String

    /// The ID of the entity that created this tool call.
    public let createdBy: String?

    private enum CodingKeys: String, CodingKey {
        case action
        case callID = "call_id"
        case id
        case status
        case type
        case createdBy = "created_by"
    }
}

/// Execute a shell command.
nonisolated public struct OpenAIFunctionShellAction: Decodable, Sendable {
    /// A list of commands to run.
    public let commands: [String]

    /// Optional maximum number of characters to return from each command.
    public let maxOutputLength: Int?

    /// Optional timeout in milliseconds for the commands.
    public let timeoutMs: Int?

    private enum CodingKeys: String, CodingKey {
        case commands
        case maxOutputLength = "max_output_length"
        case timeoutMs = "timeout_ms"
    }
}
