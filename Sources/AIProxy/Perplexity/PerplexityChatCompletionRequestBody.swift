public struct PerplexityChatCompletionRequestBody: Encodable {
    // Required

    /// A list of messages comprising the conversation so far.
    /// After the (optional) system message, user and assistant roles should alternate with
    /// user then assistant, ending in user.
    public let messages: [Message]

    /// The name of the model that will complete your prompt.
    /// Refer to Supported Models to find all the models offered:
    /// https://docs.perplexity.ai/guides/model-cards
    public let model: String


    // Optional

    /// A multiplicative penalty greater than 0. Values greater than 1.0 penalize new tokens based
    /// on their existing frequency in the text so far, decreasing the model's likelihood to repeat
    /// the same line verbatim. A value of 1.0 means no penalty. Incompatible with
    /// presence_penalty.
    /// default: 1
    public let frequencyPenalty: Double?

    /// The maximum number of completion tokens returned by the API. The total number of tokens
    /// requested in max_tokens plus the number of prompt tokens sent in messages must not exceed
    /// the context window token limit of model requested. If left unspecified, then the model will
    /// generate tokens until either it reaches its stop token or the end of its context window.
    public let maxTokens: Int?

    /// A value between -2.0 and 2.0. Positive values penalize new tokens based on whether they
    /// appear in the text so far, increasing the model's likelihood to talk about new topics.
    /// Incompatible with frequency_penalty.
    /// default: 0
    public let presencePenalty: Double?

    /// Determines whether or not a request to an online model should return citations. Citations
    /// are in closed beta access.
    /// default: false
    public let returnCitations: Bool?

    /// Determines whether or not a request to an online model should return images. Images are in
    /// closed beta access
    /// default: false
    public let returnImages: Bool?

    /// Determines whether or not a request to an online model should return related questions.
    /// Related questions are in closed beta access
    /// default: false
    public let returnRelatedQuestions: Bool?

    /// Given a list of domains, limit the citations used by the online model to URLs from the
    /// specified domains. Currently limited to only 3 domains for whitelisting and blacklisting.
    /// For blacklisting add a `-` to the beginning of the domain string.
    public let searchDomainFilter: [String]?

    /// Returns search results within the specified time interval - does not apply to images.
    /// Values include `.month`, `.week`, `.day`, `.hour`
    public let searchRecencyFilter: SearchRecencyFilter?

    /// Determines whether or not to incrementally stream the response with server-sent events with content-type: text/event-stream.
    /// default: false
    public var stream: Bool?

    /// The amount of randomness in the response, valued between 0 inclusive and 2 exclusive.
    /// Higher values are more random, and lower values are more deterministic.
    /// default: 0.2
    public let temperature: Double?

    /// The number of tokens to keep for highest top-k filtering, specified as an integer between 0
    /// and 2048 inclusive. If set to 0, top-k filtering is disabled. We recommend either altering
    /// top_k or top_p, but not both.
    /// default: 0
    public let topK: Double?

    /// The nucleus sampling threshold, valued between 0 and 1 inclusive. For each subsequent
    /// token, the model considers the results of the tokens with top_p probability mass. We
    /// recommend either altering top_k or top_p, but not both.
    /// default: 0.9
    public let topP: Double?

    /// Options for web search, including the search context size (high, medium, low).
    /// default: medium
    public let webSearchOptions: WebSearchOptions?

    private enum CodingKeys: String, CodingKey {
        case messages
        case model

        case frequencyPenalty = "frequency_penalty"
        case maxTokens = "max_tokens"
        case presencePenalty = "presence_penalty"
        case returnCitations = "return_citations"
        case returnImages = "return_images"
        case returnRelatedQuestions = "return_related_questions"
        case searchDomainFilter = "search_domain_filter"
        case searchRecencyFilter = "search_recency_filter"
        case stream
        case temperature
        case topK = "top_k"
        case topP = "top_p"
        case webSearchOptions = "web_search_options"
    }

    // This memberwise initializer is autogenerated.
    // To regenerate, use `cmd-shift-a` > Generate Memberwise Initializer
    // To format, place the cursor in the initializer's parameter list and use `ctrl-m`
    public init(
        messages: [PerplexityChatCompletionRequestBody.Message],
        model: String,
        frequencyPenalty: Double? = nil,
        maxTokens: Int? = nil,
        presencePenalty: Double? = nil,
        returnCitations: Bool? = nil,
        returnImages: Bool? = nil,
        returnRelatedQuestions: Bool? = nil,
        searchDomainFilter: [String]? = nil,
        searchRecencyFilter: PerplexityChatCompletionRequestBody.SearchRecencyFilter? = nil,
        stream: Bool? = nil,
        temperature: Double? = nil,
        topK: Double? = nil,
        topP: Double? = nil,
        webSearchOptions: WebSearchOptions? = nil
    ) {
        self.messages = messages
        self.model = model
        self.frequencyPenalty = frequencyPenalty
        self.maxTokens = maxTokens
        self.presencePenalty = presencePenalty
        self.returnCitations = returnCitations
        self.returnImages = returnImages
        self.returnRelatedQuestions = returnRelatedQuestions
        self.searchDomainFilter = searchDomainFilter
        self.searchRecencyFilter = searchRecencyFilter
        self.stream = stream
        self.temperature = temperature
        self.topK = topK
        self.topP = topP
        self.webSearchOptions = webSearchOptions
    }
}

// MARK: - RequestBody.Message
extension PerplexityChatCompletionRequestBody {
    public enum Message: Encodable {
        case assistant(content: String)
        case system(content: String)
        case user(content: String)

        private enum RootKey: String, CodingKey {
            case content
            case role
        }

        public func encode(to encoder: any Encoder) throws {
            var container = encoder.container(keyedBy: RootKey.self)
            switch self {
            case .assistant(let content):
                try container.encode(content, forKey: .content)
                try container.encode("assistant", forKey: .role)
            case .system(let content):
                try container.encode(content, forKey: .content)
                try container.encode("system", forKey: .role)
            case .user(let content):
                try container.encode(content, forKey: .content)
                try container.encode("user", forKey: .role)
            }
        }
    }
}

// MARK: - RequestBody.SearchRecencyFilter
extension PerplexityChatCompletionRequestBody {
    public enum SearchRecencyFilter: String, Encodable {
        case hour
        case day
        case week
        case month
    }
}

// MARK: - RequestBody.WebSearchOptions
extension PerplexityChatCompletionRequestBody {
    public struct WebSearchOptions: Encodable {
        public let searchContextSize: SearchContextSize

        private enum CodingKeys: String, CodingKey {
            case searchContextSize = "search_context_size"
        }

        public init(searchContextSize: SearchContextSize) {
            self.searchContextSize = searchContextSize
        }
    }

    public enum SearchContextSize: String, Encodable {
        case high
        case medium
        case low
    }
}
